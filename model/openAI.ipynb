{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import PyPDF2\n",
    "import pptx\n",
    "from pptx.util import Inches\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(prompt, max_tokens=2048):\n",
    "    completion = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=max_tokens)\n",
    "    return completion.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(filename='research_paper.pdf'):\n",
    "    research_paper = \"\"\n",
    "    pdf_file = open(filename, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        research_paper ++ page_text\n",
    "    return research_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_by_page_summary(filename='research_paper.pdf'):\n",
    "    research_paper = \"\"\n",
    "    pdf_file = open(filename, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        summarised_page = respond(f\"Summarise page {page_num+1}:\\n{page_text}\")\n",
    "        research_paper += summarised_page\n",
    "    return research_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_summary(filename='research_paper.pdf', max_tokens=2048):\n",
    "    research_paper = extract_text(filename=filename)\n",
    "    summary = respond(f\"Summarise this research paper:\\n{research_paper}\", max_tokens=max_tokens)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(filename='research_paper.pdf', max_tokens=1000):\n",
    "    research_paper = page_by_page_summary(filename=filename)\n",
    "    resp = respond(f\"Return only a suitable title for this research paper:\\n{research_paper}\", max_tokens=max_tokens)\n",
    "    resp = resp.split('\\n')\n",
    "    title = [sentence for sentence in resp if sentence!=\"\"][-1]\n",
    "    title = title.strip()\n",
    "    if title[0]=='\"' and title[-1]=='\"': title = title[1:-1]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_insights(filename='research_paper.pdf'):\n",
    "    insights = []\n",
    "    pdf_file = open(filename, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        page_text = page.extract_text()\n",
    "        page_insights = respond(f\"List in bullet points only the key insights of page {page_num+1}:\\n{page_text}\")\n",
    "        page_insights = page_insights.replace('\\n', ' ')\n",
    "\n",
    "        if '•' in page_insights: page_insights = page_insights.split('•')\n",
    "        elif '- ' in page_insights: page_insights = page_insights.split('- ')\n",
    "        else: page_insights = page_insights.split(' -')\n",
    "\n",
    "        page_insights = [insight.strip() for insight in page_insights if len(insight.strip())>13]\n",
    "        insights.append(page_insights)\n",
    "    return insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ppt(filename='research_paper.pdf', output='research_paper.pptx'):\n",
    "    title = get_title(filename=filename)\n",
    "    insights = key_insights(filename=filename)\n",
    "\n",
    "    # Create a PowerPoint presentation with the key insights\n",
    "    ppt = pptx.Presentation()\n",
    "    # Add title slide\n",
    "    slide = ppt.slides.add_slide(ppt.slide_layouts[1])\n",
    "    Title = slide.shapes.title\n",
    "    Title.text = title\n",
    "    # img = slide.shapes.add_picture('image.jpg', Inches(4), Inches(4), height=Inches(2))\n",
    "    # Add all other content slides\n",
    "    for i in range(len(insights)):\n",
    "        slide = ppt.slides.add_slide(ppt.slide_layouts[1])\n",
    "        title = slide.shapes.title\n",
    "        title.text = f\"Page {i+1}\"\n",
    "        body = slide.placeholders[1]\n",
    "        content = \"\\n\".join(insights[i])\n",
    "        body.text = content\n",
    "        # img = slide.shapes.add_picture('image.jpg', Inches(4), Inches(4), height=Inches(2))\n",
    "    ppt.save(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_image(prompt, filename=\"image.jpg\"):\n",
    "    response = openai.Image.create(\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    urllib.request.urlretrieve(image_url, filename)\n",
    "    img = Image.open(filename)\n",
    "    img.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This paper discusses the forecasting of prices of alternative assets.', 'It was written by Samay Panwar in 2021.', 'The paper can be accessed from Nanyang Technological University and DR-NTU.', 'The paper was downloaded from DR-NTU.', \"This paper is published in 2021 under the author's name.\"], ['Cryptocurrencies provide a sort of a sink for excess funds to keep inflationary pressures at bay', 'There is limited research devoted to forecasting or studying the properties of cryptocurrency time series', 'Attempts have been made to forecast cryptocurrency prices with a variety of machine learning algorithms', 'Alternative data such as tweets and news headlines have been used as exogenous factors into language models', 'Data was collected from https://www.cryptodatadownload.com/data/gemini/ and was cleaned by indexing and filling NaN values'], ['Transform to check for seasonality and outliers.   Key Insights:', 'Cryptocurrencies do not follow a Gaussian distribution, instead follow some form of gamma or Cauchy distribution.', 'Skewness and Autocorrelation was noted in the data.', 'Fat tails were also evident in the boxplot.', 'The data is not stationary and follows a t-distribution.', 'Cointegration and Granger Causality were tested and the lag of the predictor series was noted.', 'The residuals were tested for endogeneity, heteroskedasticity and outliers.'], ['Noise is clipped from the residuals before they are passed on to the LSTM model', 'LSTM model consists of two layers, coupled with Dropout layers and a batch size of 32 observations plus three densely connected layers with a ReLu activation function', 'Results indicate that our hybrid RLM-LSTM model was able to successfully forecast better than a naïve baseline model, achieving an rMAPE of 0.684'], ['learning techniques,”  J. Appl. Intell. F in. , vol.  7, no. 1, pp. 35 – 41, 2020.    Key Insights:', 'Developed a hybrid model using recurrent neural networks (RNN) – Long Short-Term Memory (LSTM) to forecast cryptocurrency prices', 'A simulated trading strategy where a unit of the cryptocurrency was bought when the model forecast an increase in price, and sold when the model forecast a decrease in price was shown to yield returns of 15.16% from a portfolio of 10,000$', 'Cryptocurrencies are largely sentiment-driven and cause steep bull and bear runs which contribute to its characteristic high volatility', 'Further research can be conducted with the use of rolling or expanding models as well as ensemble models to achieve better results'], ['Artificial intelligence (AI) techniques can be applied to cryptocurrency data to identify trends, classify variables, and predict future market fluctuations.', 'Deep learning techniques have been successfully employed to classify cryptocurrency time series and predict trends in Bitcoin transactions.', 'Machine learning algorithms and natural language processing methods have been used to analyze user comments and replies in order to predict fluctuations in cryptocurrency transactions.']]\n"
     ]
    }
   ],
   "source": [
    "insights = key_insights()\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f1df718a6c515dc365c5760bf132252de6d3181b8a567de9c33549baf110d64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
